{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9008bbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\virtualenvs\\venv_emotion_tf\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\users\\user\\virtualenvs\\venv_emotion_tf\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "c:\\users\\user\\virtualenvs\\venv_emotion_tf\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "from imutils import face_utils\n",
    "import imutils\n",
    "import time\n",
    "import dlib\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import logging\n",
    "logging.disable(logging.INFO)\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d563abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b073fb",
   "metadata": {},
   "source": [
    "# Data Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "846e2563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dlib's face detector (HOG-based) and then create the facial landmark predictor\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abeffa7f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 0 rows.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mood</th>\n",
       "      <th>vectors</th>\n",
       "      <th>coords</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S076_005_00000001.png</th>\n",
       "      <td>neutral</td>\n",
       "      <td>[-2.6322915095877812, -2.494540708721434, -2.4...</td>\n",
       "      <td>[-0.8730854600909741, -0.48756720498586864, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S062_002_00000016.png</th>\n",
       "      <td>surprise</td>\n",
       "      <td>[-2.7791600237608067, -2.712864574315995, 2.42...</td>\n",
       "      <td>[-0.9346377155531771, -0.2973847276760109, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S116_007_00000001.png</th>\n",
       "      <td>neutral</td>\n",
       "      <td>[-2.655350020502288, -2.5584892579457503, -2.5...</td>\n",
       "      <td>[-0.8840949402949303, -0.46730732558446314, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S062_001_00000017.png</th>\n",
       "      <td>fear</td>\n",
       "      <td>[-2.8367034975988674, -2.759683721081592, 2.45...</td>\n",
       "      <td>[-0.9535969333632888, -0.2925808772819182, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S091_001_00000001.png</th>\n",
       "      <td>neutral</td>\n",
       "      <td>[-2.8023000391357487, -2.7611364521796538, 2.6...</td>\n",
       "      <td>[-0.9429903335828895, -0.3328201177351375, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S068_003_00000001.png</th>\n",
       "      <td>neutral</td>\n",
       "      <td>[-2.5100394114318716, -2.5017246569051292, 2.4...</td>\n",
       "      <td>[-0.8431119837031122, -0.35956246363809197, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S102_009_00000015.png</th>\n",
       "      <td>disgust</td>\n",
       "      <td>[-2.4851758380436046, -2.4377067036305955, 2.4...</td>\n",
       "      <td>[-0.8345688170856242, -0.3595065673599612, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S089_001_00000016.png</th>\n",
       "      <td>surprise</td>\n",
       "      <td>[-1.9806208314725477, -1.9291183215750334, 1.7...</td>\n",
       "      <td>[-0.6620256855279523, -0.3259203374906842, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S083_003_00000001.png</th>\n",
       "      <td>neutral</td>\n",
       "      <td>[-2.628534744180754, -2.591422876336479, -2.65...</td>\n",
       "      <td>[-0.8712476277448775, -0.4908437339407761, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S093_001_00000001.png</th>\n",
       "      <td>neutral</td>\n",
       "      <td>[-2.6651558248602534, -2.596148222820884, -0.0...</td>\n",
       "      <td>[-0.8918465515396763, -0.42808634473904467, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           mood  \\\n",
       "filename                          \n",
       "S076_005_00000001.png   neutral   \n",
       "S062_002_00000016.png  surprise   \n",
       "S116_007_00000001.png   neutral   \n",
       "S062_001_00000017.png      fear   \n",
       "S091_001_00000001.png   neutral   \n",
       "S068_003_00000001.png   neutral   \n",
       "S102_009_00000015.png   disgust   \n",
       "S089_001_00000016.png  surprise   \n",
       "S083_003_00000001.png   neutral   \n",
       "S093_001_00000001.png   neutral   \n",
       "\n",
       "                                                                 vectors  \\\n",
       "filename                                                                   \n",
       "S076_005_00000001.png  [-2.6322915095877812, -2.494540708721434, -2.4...   \n",
       "S062_002_00000016.png  [-2.7791600237608067, -2.712864574315995, 2.42...   \n",
       "S116_007_00000001.png  [-2.655350020502288, -2.5584892579457503, -2.5...   \n",
       "S062_001_00000017.png  [-2.8367034975988674, -2.759683721081592, 2.45...   \n",
       "S091_001_00000001.png  [-2.8023000391357487, -2.7611364521796538, 2.6...   \n",
       "S068_003_00000001.png  [-2.5100394114318716, -2.5017246569051292, 2.4...   \n",
       "S102_009_00000015.png  [-2.4851758380436046, -2.4377067036305955, 2.4...   \n",
       "S089_001_00000016.png  [-1.9806208314725477, -1.9291183215750334, 1.7...   \n",
       "S083_003_00000001.png  [-2.628534744180754, -2.591422876336479, -2.65...   \n",
       "S093_001_00000001.png  [-2.6651558248602534, -2.596148222820884, -0.0...   \n",
       "\n",
       "                                                                  coords  \n",
       "filename                                                                  \n",
       "S076_005_00000001.png  [-0.8730854600909741, -0.48756720498586864, -0...  \n",
       "S062_002_00000016.png  [-0.9346377155531771, -0.2973847276760109, -0....  \n",
       "S116_007_00000001.png  [-0.8840949402949303, -0.46730732558446314, -0...  \n",
       "S062_001_00000017.png  [-0.9535969333632888, -0.2925808772819182, -0....  \n",
       "S091_001_00000001.png  [-0.9429903335828895, -0.3328201177351375, -0....  \n",
       "S068_003_00000001.png  [-0.8431119837031122, -0.35956246363809197, -0...  \n",
       "S102_009_00000015.png  [-0.8345688170856242, -0.3595065673599612, -0....  \n",
       "S089_001_00000016.png  [-0.6620256855279523, -0.3259203374906842, -0....  \n",
       "S083_003_00000001.png  [-0.8712476277448775, -0.4908437339407761, -0....  \n",
       "S093_001_00000001.png  [-0.8918465515396763, -0.42808634473904467, -0...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create prelim df with filename and target emotion class (mood)\n",
    "data_path = 'dataset/'\n",
    "dataset1, dataset2 = 'ck', 'mux'\n",
    "model_path = 'trained_models/'\n",
    "moods = [k for k in os.listdir(data_path + dataset1 + '/') if '.' not in k]\n",
    "\n",
    "# load vectors & coords df\n",
    "def getVectorsData(dataset):\n",
    "    df = None\n",
    "    if os.path.isfile(data_path + dataset + '/df_vector_coods.csv'):\n",
    "        df = pd.read_csv(data_path + dataset + '/df_vector_coods.csv', index_col='filename')\n",
    "        df['vectors'] = df['vectors'].apply(json.loads)\n",
    "        df['coords'] = df['coords'].apply(json.loads)\n",
    "\n",
    "        indexNames = df[(df.vectors.str.len().eq(0)) | (df.coords.str.len().eq(0))].index \n",
    "        indexNames = list(indexNames)\n",
    "        for index,row in df.iterrows():\n",
    "            if len(row['vectors']) != 68:\n",
    "                indexNames.append(index)\n",
    "        print('Deleted',len(indexNames),'rows.')\n",
    "        df.drop(indexNames , inplace=True)\n",
    "    else:\n",
    "        print('[%s] Vectors & coords data does not exist.' % dataset)\n",
    "    return df\n",
    "\n",
    "df_ck = getVectorsData(dataset1)\n",
    "# df_mux = getVectorsData(dataset2)\n",
    "    \n",
    "display(df_ck.sample(10))\n",
    "# display(df_mux.sample(10))\n",
    "    \n",
    "# load graylevels Numpy arrays\n",
    "def getGrayLevelsData(dataset):\n",
    "    cropped_dataseta, cropped_target = None, None\n",
    "    file_path = data_path + dataset + '/graylevels_data_no_contempt.npy'\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            cropped_dataset = np.load(f)\n",
    "            cropped_target = np.load(f)\n",
    "    else:\n",
    "        print('Graylevels data does not exist.')\n",
    "    return cropped_dataset, cropped_target\n",
    "\n",
    "ck_cropped_dataset, ck_cropped_target = getGrayLevelsData(dataset1)\n",
    "# mux_cropped_dataset, mux_cropped_target = getGrayLevelsData(dataset2)\n",
    "\n",
    "dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bab7347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for finding vector magnitude and direction\n",
    "def mag(pointA, pointB):\n",
    "    x = pointA[0] - pointB[0]\n",
    "    y = pointA[1] - pointB[1]\n",
    "    return math.sqrt(x*x + y*y)\n",
    "\n",
    "# find angle between two points (-pi to pi rads)\n",
    "def angle(cog, point):\n",
    "    x = point[0] - cog[0]\n",
    "    y = point[1] - cog[1]\n",
    "    \n",
    "    if not x:\n",
    "        return math.pi/2 if y>0 else -math.pi/2\n",
    "        \n",
    "    angle = math.atan(y/x)\n",
    "    if x<0 and y>0: # 2nd quadrant\n",
    "        angle += math.pi\n",
    "    elif x<0 and y<0: # 3rd quadrant\n",
    "        angle -= math.pi\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e9793b",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "814782c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, Dropout, Flatten, BatchNormalization, Activation\n",
    "from keras.layers import GlobalAveragePooling2D, Conv2D, MaxPooling2D\n",
    "from keras.layers import GlobalAveragePooling1D, Conv1D, MaxPooling1D\n",
    "from keras.models import Sequential, load_model\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37c3214",
   "metadata": {},
   "source": [
    "## Functions\n",
    "The following functions are used for building, training and evaluation of CNN models for inputs of vectors, coordinates and image graylevels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77135a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(moods)\n",
    "\n",
    "def build_cnn(model_name, model_num, input_shape):\n",
    "    print('Building model...', end=' ')\n",
    "    model = Sequential()\n",
    "\n",
    "    # CS3237 model for coords & vectors\n",
    "    if model_num == 1:\n",
    "        model.add(Conv1D(32, kernel_size=5, activation='relu', input_shape=input_shape, padding='same'))\n",
    "        model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "        model.add(Conv1D(64, kernel_size=5, activation='relu'))\n",
    "        model.add(Conv1D(128, kernel_size=5, activation='relu'))\n",
    "        model.add(Conv1D(64, kernel_size=5, activation='relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1024, activation='relu'))\n",
    "        model.add(Dropout(0.1))\n",
    "\n",
    "    # Ansamma's model\n",
    "    if model_num == 2:\n",
    "        model.add(Conv1D(64, kernel_size=5, activation='relu', input_shape=input_shape, padding='same'))\n",
    "        model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "        model.add(Conv1D(128, kernel_size=3, activation='relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "        model.add(Conv1D(512, kernel_size=3, activation='relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "        model.add(Conv1D(512, kernel_size=3, activation='relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "        model.add(Dropout(0.1))\n",
    "\n",
    "    # CS3237 model for image graylevels\n",
    "    if model_num == 3:\n",
    "        model.add(Conv2D(32, kernel_size=(5,5), activation='relu', input_shape=input_shape, padding='same'))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "        model.add(Conv2D(64, kernel_size=(5,5), activation='relu'))\n",
    "#         model.add(Conv2D(128, kernel_size=(5,5), activation='relu'))\n",
    "#         model.add(Conv2D(64, kernel_size=(5,5), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(50, activation='relu'))\n",
    "        model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    print('Model built.')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61a8333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cnn(model, data, epochs, model_name, verbose=False, plots=True):\n",
    "    \n",
    "    x_train, y_train, x_val, y_val, x_test, y_test = data[0], data[1], data[2], data[3], data[4], data[5]\n",
    "#     opt = Adam(learning_rate = 0.0001)\n",
    "    opt = SGD(learning_rate=0.01, momentum=0.7)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    savemodel = ModelCheckpoint(model_name)\n",
    "    stopmodel = EarlyStopping(min_delta=0.001, patience=10)\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    start = time.time()\n",
    "    history = model.fit(x=x_train, y=y_train, batch_size=64,\n",
    "              validation_data=(x_val,y_val), shuffle=True,\n",
    "              epochs=epochs, verbose=verbose,\n",
    "              callbacks=[savemodel,stopmodel])\n",
    "    end = time.time()\n",
    "    tt = end - start\n",
    "    print(\"Done (%d epochs). Time taken: %dm%ds.\" % (len(history.history['loss']), tt//60, tt%60))\n",
    "    \n",
    "    if plots:\n",
    "        # plot loss\n",
    "        plt.title('Cross Entropy Loss')\n",
    "        plt.plot(history.history['loss'], color='blue', label='train')\n",
    "        plt.plot(history.history['val_loss'], color='orange', label='validation')\n",
    "        ymax = max([1, max(history.history['loss'])+0.05, max(history.history['val_loss'])+0.05])\n",
    "        plt.ylim(0,ymax)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        # plot accuracy\n",
    "        plt.title('Classification Accuracy')\n",
    "        plt.plot(history.history['accuracy'], color='blue', label='train')\n",
    "        plt.plot(history.history['val_accuracy'], color='orange', label='validation')\n",
    "        plt.ylim(0,1)\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd66cc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cnn(model_name, data, tag=\"\"):\n",
    "    tag += \" \" if tag else \"\"\n",
    "    model = load_model(model_name)\n",
    "    x_train, y_train, x_val, y_val, x_test, y_test = data[0], data[1], data[2], data[3], data[4], data[5]\n",
    "    loss_tr, acc_tr = model.evaluate(x=x_train, y=y_train, verbose=False)\n",
    "    loss_val, acc_val = model.evaluate(x=x_val, y=y_val, verbose=False)\n",
    "    loss_ts, acc_ts = model.evaluate(x=x_test, y=y_test, verbose=False)\n",
    "    print(tag + 'Train accuracy: %.4f, loss: %.4f' % (acc_tr, loss_tr))\n",
    "    print(tag + 'Validation accuracy: %.4f, loss: %.4f' % (acc_val, loss_val))\n",
    "    print(tag + 'Test accuracy: %4.3f, loss: %4.3f' % (acc_ts, loss_ts))\n",
    "    return (acc_tr, acc_val, acc_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca20c96",
   "metadata": {},
   "source": [
    "## CNN\n",
    "CNN models trained on vectors and coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159b62a6",
   "metadata": {},
   "source": [
    "### CNN Datasets\n",
    "Separate datasets ```cnn_vectors_only_data``` and ```cnn_vectors_coords_data``` for dataset with vectors only and dataset with both vectors and coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8ccd59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One hot encoding for emotion\n",
    "cnn_ck_data = pd.get_dummies(df_ck.mood).join(df_ck.loc[:,['vectors','coords']])\n",
    "emotion_classes = cnn_ck_data.columns[:len(moods)]\n",
    "print('One hot encoded:')\n",
    "display(cnn_ck_data.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd7e018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for emotion\n",
    "cnn_mux_data = pd.get_dummies(df_mux.mood).join(df_mux.loc[:,['vectors','coords']])\n",
    "emotion_classes = cnn_mux_data.columns[:len(moods)]\n",
    "print('One hot encoded:')\n",
    "display(cnn_mux_data.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6649a0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for vectors only\n",
    "# split into train, val and test\n",
    "x = np.array([k for k in cnn_ck_data['vectors'].values])\n",
    "y = cnn_ck_data.iloc[:,:8].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=0)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.20, random_state=0)\n",
    "\n",
    "# reshape for CNN\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "x_val = x_val.reshape(x_val.shape[0], x_val.shape[1], 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], 1)\n",
    "\n",
    "cnn_vectors_only_data = [x_train, y_train, x_val, y_val, x_test, y_test]\n",
    "\n",
    "print('(Vectors Only) Train X shape:', x_train.shape)\n",
    "print('(Vectors Only) Train Y shape:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f9a58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for vectors & coords\n",
    "# split into train, val and test\n",
    "x = np.c_[np.array([k for k in cnn_mux_data['vectors'].values]), np.array([k for k in cnn_mux_data['coords'].values])]\n",
    "y = cnn_mux_data.iloc[:,:8].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=0)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.20, random_state=0)\n",
    "\n",
    "# reshape for CNN\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "x_val = x_val.reshape(x_val.shape[0], x_val.shape[1], 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], 1)\n",
    "\n",
    "cnn_vectors_coords_data = [x_train, y_train, x_val, y_val, x_test, y_test]\n",
    "\n",
    "print('(Vectors & Coords) Train X shape:', x_train.shape)\n",
    "print('(Vectors & Coords) Train Y shape:', y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafc57b0",
   "metadata": {},
   "source": [
    "### CNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ab3501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN1: CS3237 model (Vectors only)\n",
    "MODEL_NAME = model_path + 'emotion-cnn4.hd5'\n",
    "model = build_cnn(MODEL_NAME, 1, (cnn_vectors_only_data[0].shape[1],1))\n",
    "train_cnn(model, cnn_vectors_only_data, 200, MODEL_NAME)\n",
    "cnn1_acc = evaluate_cnn(MODEL_NAME, cnn_vectors_only_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce16fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN2: Ansamma's model (Vectors only)\n",
    "MODEL_NAME = model_path + 'emotion-cnn5.hd5'\n",
    "model = build_cnn(MODEL_NAME, 2, (68,1))\n",
    "train_cnn(model, cnn_vectors_only_data, 200, MODEL_NAME)\n",
    "cnn2_acc = evaluate_cnn(MODEL_NAME, cnn_vectors_only_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc89e19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CNN3: CS3237 model (Vectors & coords)\n",
    "MODEL_NAME = model_path + 'emotion-cnn6.hd5'\n",
    "model = build_cnn(MODEL_NAME, 1, (cnn_vectors_coords_data[0].shape[1],1))\n",
    "train_cnn(model, cnn_vectors_coords_data, 200, MODEL_NAME)\n",
    "cnn3_acc = evaluate_cnn(MODEL_NAME, cnn_vectors_coords_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7783598f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn1_acc = evaluate_cnn(model_path + 'emotion-cnn4.hd5', cnn_vectors_only_data, 'CNN1')\n",
    "print()\n",
    "cnn2_acc = evaluate_cnn(model_path + 'emotion-cnn5.hd5', cnn_vectors_only_data, 'CNN2')\n",
    "print()\n",
    "cnn3_acc = evaluate_cnn(model_path + 'emotion-cnn6.hd5', cnn_vectors_coords_data, 'CNN3')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f00957",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20c8c6e",
   "metadata": {},
   "source": [
    "### SVM Datasets\n",
    "Separate datasets ```svm_vectors_only_data``` and ```svm_vectors_coords_data``` for dataset with vectors only and dataset with both vectors and coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de19fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding for SVM\n",
    "svm_data = df.copy()\n",
    "le = LabelEncoder()\n",
    "svm_data['mood'] = le.fit_transform(svm_data['mood'].values)\n",
    "svm_classes = list(le.inverse_transform(np.arange(0,8)))\n",
    "print('Label encoded:')\n",
    "display(svm_data.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1ef243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for vectors only\n",
    "# split into train, val and test\n",
    "x = np.array([k for k in svm_data['vectors'].values])\n",
    "y = svm_data['mood'].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=0)\n",
    "\n",
    "svm_vectors_only_data = [x_train, y_train, x_test, y_test]\n",
    "\n",
    "print('(Vectors only) Train X shape:', x_train.shape)\n",
    "print('(Vectors only) Train Y shape:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72087f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for vectors & coords\n",
    "# split into train, val and test\n",
    "x = np.c_[np.array([k for k in svm_data['vectors'].values]), np.array([k for k in svm_data['coords'].values])]\n",
    "y = svm_data['mood'].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=0)\n",
    "\n",
    "svm_vectors_coords_data = [x_train, y_train, x_test, y_test]\n",
    "\n",
    "print('(Vectors & Coords) Train X shape:', x_train.shape)\n",
    "print('(Vectors & Coords) Train Y shape:', y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e497e72",
   "metadata": {},
   "source": [
    "### SVM Functions\n",
    "Functions for building, training and evaluation of SVM models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c31ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(x_train, y_train):\n",
    "#     params = {'C':[10e-3, 10e-2, 0.1, 1, 10], 'kernel':('linear', 'poly', 'rbf', 'sigmoid'), 'decision_function_shape':('ovr', 'ovo')}\n",
    "    params = {'C':[10e-2, 0.1, 1]}\n",
    "    svm_pipe = Pipeline([('scaler', StandardScaler()), \n",
    "                       ('svm', GridSearchCV(svm.SVC(max_iter=100000, probability=True, kernel='linear', decision_function_shape='ovr'), params)), ])\n",
    "#     svm_pipe = Pipeline([('scaler', StandardScaler()), \n",
    "#                        ('svm', svm.SVC(max_iter=100000, probability=True, kernel='linear', decision_function_shape='ovr'), params), ])\n",
    "    start = time.time()\n",
    "    svm_pipe.fit(x_train, y_train)\n",
    "    end = time.time()\n",
    "    print('SVM model trained. Time taken: %.3fs.' % (end-start))\n",
    "    print('Best params:', svm_pipe['svm'].best_params_)\n",
    "    \n",
    "    return svm_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df1e927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_svm(svm, data, name):\n",
    "    if isinstance(svm, str):\n",
    "        svm = pickle.load(open(model_path+svm, 'rb'))\n",
    "    \n",
    "    x_train, y_train, x_test, y_test = data[0], data[1], data[2], data[3]\n",
    "    \n",
    "    # Prediction\n",
    "    y_train_pred = svm.predict(x_train)\n",
    "    y_test_pred = svm.predict(x_test)\n",
    "\n",
    "    # Evaluation\n",
    "    acc_tr = accuracy_score(y_train, y_train_pred)\n",
    "    acc_ts = accuracy_score(y_test, y_test_pred)\n",
    "    print('%s Train accuracy: %.4f' % (name, acc_tr))\n",
    "    print('%s Test accuracy: %.4f' % (name, acc_ts))\n",
    "    \n",
    "    return (acc_tr, None, acc_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3b6a81",
   "metadata": {},
   "source": [
    "### SVM1: Vectors only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c089d048",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm1 = train_svm(svm_vectors_only_data[0], svm_vectors_only_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8daf72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm1_acc = evaluate_svm(svm1, svm_vectors_only_data, 'SVM1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27012ac",
   "metadata": {},
   "source": [
    "### SVM2: Vectors & Coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2e8b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm2 = train_svm(svm_vectors_coords_data[0], svm_vectors_coords_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245659ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm2_acc = evaluate_svm(svm2, svm_vectors_coords_data, 'SVM2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41da525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models\n",
    "pickle.dump(svm1, open(model_path + 'emotion-svm3', 'wb'))\n",
    "pickle.dump(svm2, open(model_path + 'emotion-svm4', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401f08bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm1_acc = evaluate_svm('emotion-svm3', svm_vectors_only_data, 'SVM1')\n",
    "print()\n",
    "svm2_acc = evaluate_svm('emotion-svm4', svm_vectors_coords_data, 'SVM2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09ee1fc",
   "metadata": {},
   "source": [
    "## Cropped Images\n",
    "Model input is pixel graylevels instead of vectors/coordinates. CNN is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f99bdfd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generateGraylevelDataset(cropped_dataset, cropped_target):\n",
    "    cropped_target = LabelEncoder().fit_transform(cropped_target)\n",
    "    \n",
    "    # train-test-val split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(cropped_dataset, cropped_target, test_size=0.20, random_state=0)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.20, random_state=0)\n",
    "\n",
    "    # reshape for CNN (samples, w, h, c)\n",
    "    x_train = x_train.reshape(x_train.shape[0], dim, dim, 1)\n",
    "    x_val = x_val.reshape(x_val.shape[0], dim, dim, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], dim, dim, 1)\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_val = x_val.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "\n",
    "    # normalization\n",
    "    x_train /= 255.0\n",
    "    x_val /= 255.0\n",
    "    x_test /= 255.0\n",
    "\n",
    "    # one-hot encoding\n",
    "    num_classes = len(moods)\n",
    "    y_train = to_categorical(y_train, num_classes)\n",
    "    y_val = to_categorical(y_val, num_classes)\n",
    "    y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "    print('Train X shape:', x_train.shape)\n",
    "    print('Train Y shape:', y_train.shape)\n",
    "    \n",
    "    return [x_train, y_train, x_val, y_val, x_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c282aeca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X shape: (576, 50, 50, 1)\n",
      "Train Y shape: (576, 8)\n",
      "Building model... Model built.\n",
      "Starting training...\n",
      "Done (61 epochs). Time taken: 0m55s.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8854, loss: 0.2788\n",
      "Validation accuracy: 0.8207, loss: 0.7077\n",
      "Test accuracy: 0.867, loss: 0.501\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = model_path + 'emotion-cnnC.hd5'\n",
    "ck_graylevels_data = generateGraylevelDataset(ck_cropped_dataset, ck_cropped_target)\n",
    "model = build_cnn(MODEL_NAME, 3, (dim, dim, 1))\n",
    "train_cnn(model, ck_graylevels_data, 100, MODEL_NAME, verbose=False)\n",
    "cnnA_acc = evaluate_cnn(MODEL_NAME, ck_graylevels_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd555b79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = model_path + 'emotion-cnnB.hd5'\n",
    "mux_graylevels_data = generateGraylevelDataset(mux_cropped_dataset, mux_cropped_target)\n",
    "model = build_cnn(MODEL_NAME, 3, (dim, dim, 1))\n",
    "train_cnn(model, mux_graylevels_data, 100, MODEL_NAME, verbose=False)\n",
    "cnnB_acc = evaluate_cnn(MODEL_NAME, mux_graylevels_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efdd16b",
   "metadata": {},
   "source": [
    "# Comparison\n",
    "This section is for comparison between models. I'll compare their accuracies, then I'll test the models on random images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade8a2a9",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b49f7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = [cnn1_acc, cnn2_acc, cnn3_acc, svm1_acc, svm2_acc, cnnA_acc]\n",
    "evaluate_dict = {\n",
    "    'Model': ['CNN1','CNN2','CNN3','SVM1','SVM2','CNNA'],\n",
    "    'Inputs': ['Vectors only','Vectors only','Vectors & coords','Vectors only','Vectors & coords','Pixel graylevels'],\n",
    "    'Train acc': [k[0] for k in accuracies],\n",
    "    'Val acc': [k[1] for k in accuracies],\n",
    "    'Test acc': [k[2] for k in accuracies]\n",
    "}\n",
    "evaluate_df = pd.DataFrame(evaluate_dict)\n",
    "evaluate_df.set_index('Model', inplace=True)\n",
    "display(evaluate_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7746b097",
   "metadata": {},
   "source": [
    "## Testing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a87404",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# get all image filenames\n",
    "image_filenames = []\n",
    "dataset = dataset2\n",
    "for root, dirs, files in os.walk(data_path + dataset + '/'):\n",
    "    dir = os.path.basename(root)\n",
    "    for file in files:\n",
    "        image_filenames += [data_path + dataset + '/' + dir + '/' + file]\n",
    "        \n",
    "rand_images = random.sample(image_filenames, 10) # get random images\n",
    "\n",
    "# load models\n",
    "# cnn1 = load_model(model_path+'emotion-cnn1.hd5')\n",
    "# cnn3 = load_model(model_path+'emotion-cnn3.hd5')\n",
    "# svm1 = pickle.load(open(model_path+'emotion-svm1', 'rb'))\n",
    "# svm2 = pickle.load(open(model_path+'emotion-svm2', 'rb')) \n",
    "cnnA = load_model(model_path+'emotion-cnnA.hd5')\n",
    "cnnB = load_model(model_path+'emotion-cnnB.hd5')\n",
    "\n",
    "for path in rand_images:\n",
    "    vectors, coords = [], []\n",
    "    classes = {}\n",
    "    \n",
    "    image = cv2.imread(path)\n",
    "    image = imutils.resize(image, width=400)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    rects = detector(gray, 1)\n",
    "\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape) \n",
    "\n",
    "        cog = tuple(shape.mean(axis=0).astype(int)) # get center of gravity (COG)\n",
    "\n",
    "        for (x,y) in shape:\n",
    "            cv2.line(image, (x,y), cog, (0,0,255), 1) # draw vector lines\n",
    "            cv2.circle(image, (x,y), 2, (255,0,0), -1) # image, center-coords, radius, colour, thickness(fill)\n",
    "            vectors.append([mag(cog, (x,y)), angle(cog, (x,y))]) # get vector magnitude and direction\n",
    "            coords.append([x-cog[0], y-cog[1]])\n",
    "\n",
    "        cv2.circle(image, cog, 5, (0,255,255), -1)\n",
    "        \n",
    "        (x,y,w,h) = face_utils.rect_to_bb(rect)\n",
    "        cv2.rectangle(image, (x,y), (x+w, y+h), (0,255,0), 2)\n",
    "        cv2.putText(image, \"Face #{}\".format(i+1), (x-10, y-10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n",
    "        \n",
    "        # model inputs\n",
    "        ## vectors & coords\n",
    "        vectors = np.array(vectors)\n",
    "        scale_factor = 1 / max(vectors[:,0])\n",
    "        vectors[:,0] = vectors[:,0] * scale_factor # normalize magnitudes\n",
    "        vectors = vectors[:,0] * vectors[:,1]\n",
    "        coords = (np.array(coords) * scale_factor).reshape(-1) # 1D array\n",
    "        \n",
    "        svm_vec_input = vectors.reshape(1,-1)\n",
    "        cnn_vec_input = vectors.reshape(1, len(vectors), 1)\n",
    "        svm_both_input = np.r_[vectors, coords].reshape(1,-1)\n",
    "        cnn_both_input = np.r_[vectors, coords].reshape(1, len(vectors)+len(coords), 1)\n",
    "#         print(svm_input.shape, cnn_input.shape)\n",
    "        \n",
    "        ## image graylevels\n",
    "        cnn_px_input = image[y:y+h, x:x+w] # crop to face\n",
    "        cnn_px_input = cv2.cvtColor(cnn_px_input, cv2.COLOR_RGB2GRAY) # convert to grayscale\n",
    "        cnn_px_input = cv2.equalizeHist(cnn_px_input) # equalize histogram\n",
    "        cnn_px_input = imutils.resize(cnn_px_input, width=int(dim*1.05)) # buffer of 5 pixels for cropping to 100x100\n",
    "        cnn_px_input = np.expand_dims(cnn_px_input[:dim,:dim], axis=0) # shape=(1,dim,dim)\n",
    "    \n",
    "        # prediction\n",
    "#         classes['CNN3'] = emotion_classes[np.argmax(cnn3.predict(cnn_both_input))]\n",
    "#         classes['SVM2'] = emotion_classes[svm2.predict(svm_both_input)[0]]\n",
    "#         classes['CNNA'] = emotion_classes[np.argmax(cnnA.predict(cnn_px_input))]\n",
    "        i = 1\n",
    "        for k,v in classes.items():\n",
    "            print(k,v)\n",
    "#             cv2.putText(image, '%s: %s' % (k,v), (x-20,y+h+20*i),\n",
    "#                 cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n",
    "            i += 1\n",
    "        print(cnnA.predict(cnn_px_input))\n",
    "        print(cnnB.predict(cnn_px_input))\n",
    "    \n",
    "    print(path)\n",
    "    plt.imshow(image) # adapted for jupyter\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fe1b4d",
   "metadata": {},
   "source": [
    "## Just in case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2332989",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Akmadan's model\n",
    "#         #1st CNN layer\n",
    "#         model.add(Conv2D(64,(3,3),padding = 'same',input_shape = (48,48,1)))\n",
    "#         model.add(BatchNormalization())\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "#         model.add(Dropout(0.25))\n",
    "\n",
    "#         #2nd CNN layer\n",
    "#         model.add(Conv2D(128,(5,5),padding = 'same'))\n",
    "#         model.add(BatchNormalization())\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "#         model.add(Dropout (0.25))\n",
    "\n",
    "#         #3rd CNN layer\n",
    "#         model.add(Conv2D(512,(3,3),padding = 'same'))\n",
    "#         model.add(BatchNormalization())\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "#         model.add(Dropout (0.25))\n",
    "\n",
    "#         #4th CNN layer\n",
    "#         model.add(Conv2D(512,(3,3), padding='same'))\n",
    "#         model.add(BatchNormalization())\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#         model.add(Dropout(0.25))\n",
    "\n",
    "#         model.add(Flatten())\n",
    "\n",
    "#         #Fully connected 1st layer\n",
    "#         model.add(Dense(256))\n",
    "#         model.add(BatchNormalization())\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(Dropout(0.25))\n",
    "\n",
    "#         # Fully connected layer 2nd layer\n",
    "#         model.add(Dense(512))\n",
    "#         model.add(BatchNormalization())\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(Dropout(0.25))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_emotion_tf",
   "language": "python",
   "name": "venv_emotion_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
